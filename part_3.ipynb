{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVtpTWNpImBU",
        "outputId": "88e7f6b7-6caf-496a-f490-2b38fe1b61df"
      },
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 371,
      "metadata": {
        "id": "xGRzkNeQIkGr"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import scipy.io as sio\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 372,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jugSgI--IkGt",
        "outputId": "92c8b394-4c48-40a6-bf34-fcc92f97e3c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['__header__', '__version__', '__globals__', 'train0', 'test0', 'train1', 'test1', 'train2', 'test2', 'train3', 'test3', 'train4', 'test4', 'train5', 'test5', 'train6', 'test6', 'train7', 'test7', 'train8', 'test8', 'train9', 'test9'])"
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ],
      "source": [
        "M = sio.loadmat(\"/content/drive/MyDrive/MAT4373/mnist_all.mat\")\n",
        "M.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSrTS2e4IkGv"
      },
      "source": [
        "Concatenate the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 373,
      "metadata": {
        "id": "OzqpEFhtIkGw"
      },
      "outputs": [],
      "source": [
        "training_data = np.concatenate([M['train0'], M['train1'], M['train2'], M['train3'], M['train4'], M['train5'], M['train6'], M['train7'], M['train8'], M['train9']], axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36a6UDO2IkGw"
      },
      "source": [
        "insert 1 for bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {
        "id": "juOrqjx5IkGx"
      },
      "outputs": [],
      "source": [
        "training_data = np.insert(training_data,0,1,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb48U1hDIkGx",
        "outputId": "872de294-3e41-4b0e-f434-72f07560589b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 375
        }
      ],
      "source": [
        "training_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwZNq8wFIeH5",
        "outputId": "c8768ffd-2017-4c80-a99d-5c4297b93a7b"
      },
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 376
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRbyYaBeIkGy"
      },
      "source": [
        "Concatenate the testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {
        "id": "EWfJsh5pIkGy"
      },
      "outputs": [],
      "source": [
        "testing_data = np.concatenate([M['test0'], M['test1'], M['test2'], M['test3'], M['test4'], M['test5'], M['test6'], M['test7'], M['test8'], M['test9']], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {
        "id": "4IrZBQEVIkGz"
      },
      "outputs": [],
      "source": [
        "testing_data = np.insert(testing_data,0,1,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB3g35wyIkGz",
        "outputId": "e006a1af-aa24-4b85-b204-48dcfcc9fcb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 379
        }
      ],
      "source": [
        "testing_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsA3o1KmIkG0"
      },
      "source": [
        "Create the training labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPvYGZNTIkG0",
        "outputId": "e44042a2-cc70-4a0e-f88e-f89d96544a3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]"
            ]
          },
          "metadata": {},
          "execution_count": 380
        }
      ],
      "source": [
        "training_size = [M['train0'].shape[0], M['train1'].shape[0], M['train2'].shape[0], M['train3'].shape[0], M['train4'].shape[0], M['train5'].shape[0], M['train6'].shape[0], M['train7'].shape[0], M['train8'].shape[0], M['train9'].shape[0]]\n",
        "training_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "id": "26oy70DCIkG0"
      },
      "outputs": [],
      "source": [
        "training_target = []\n",
        "for index, value in enumerate(training_size):\n",
        "    for i in range(value):\n",
        "        training_target.append(index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb_2hFG2IkG1"
      },
      "source": [
        "Create the testing labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdEDYrs6IkG1",
        "outputId": "2538bd17-f108-4570-fe90-89c0038bfddc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[980, 1135, 1032, 1010, 982, 892, 958, 1028, 974, 1009]"
            ]
          },
          "metadata": {},
          "execution_count": 382
        }
      ],
      "source": [
        "testing_size = [M['test0'].shape[0], M['test1'].shape[0], M['test2'].shape[0], M['test3'].shape[0], M['test4'].shape[0], M['test5'].shape[0], M['test6'].shape[0], M['test7'].shape[0], M['test8'].shape[0], M['test9'].shape[0]]\n",
        "testing_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {
        "id": "HzUWAmVzIkG1"
      },
      "outputs": [],
      "source": [
        "testing_target = []\n",
        "for index, value in enumerate(testing_size):\n",
        "    for i in range(value):\n",
        "        testing_target.append(index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(np.asarray(testing_target), return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2XRzS0MSpGv",
        "outputId": "d1008348-e887-4b32-baa2-dca59cba25e4"
      },
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
              " array([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009]))"
            ]
          },
          "metadata": {},
          "execution_count": 384
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, training_target = shuffle(training_data, training_target, random_state=10)"
      ],
      "metadata": {
        "id": "2rmzx7BQIsFI"
      },
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data, testing_target = shuffle(testing_data, testing_target, random_state=20)"
      ],
      "metadata": {
        "id": "XXvS1ijJI1R1"
      },
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "id": "kNSumwU3IkG1"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import math\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "class Layer_Dense:\n",
        "    def __init__(self, n_inputs=784, n_neurons=10):\n",
        "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
        "        # set bias to 0\n",
        "        self.weights = np.insert(self.weights, 0,0, axis=0)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.output = np.dot(inputs, self.weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 388,
      "metadata": {
        "id": "PyE6RxmeIkG2"
      },
      "outputs": [],
      "source": [
        "class Activation_Softmax:\n",
        "    def forward(self, inputs):\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "        self.output = probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "id": "cKX0mzSdIkG3"
      },
      "outputs": [],
      "source": [
        "# calculate log loss\n",
        "def calculate_loss(y_pred, y_true):\n",
        "  # clip values to prevent infinity problems\n",
        "  y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7)\n",
        "  correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
        "  # Calculate the negative log value to find the loss for each element in the batch\n",
        "  negative_log_likelihoods = -np.log(correct_confidences)\n",
        "  # Calculate the average loss of the batch using the mean\n",
        "  return np.mean(negative_log_likelihoods)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encode the target variable\n",
        "def encode(target, size=10):\n",
        "    encoded = np.zeros(shape=(target.shape[0],size))\n",
        "    for i in range(target.shape[0]):\n",
        "        encoded[i][target[i]] = 1\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "xhINhNuskRNW"
      },
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {
        "id": "JraSdtYtIkG3"
      },
      "outputs": [],
      "source": [
        "# # def encode(target, size=10):\n",
        "# #     encoded = np.zeros(shape=(size))\n",
        "# #     encoded[target] = 1\n",
        "# #     return encoded\n",
        "    \n",
        "    \n",
        "# def calculate_derivatives(probabilities,input,target):\n",
        "#     # probabilities is of shape (50, 10)\n",
        "#     # input is of shape (50, 785)\n",
        "#     # target is of shape (50)\n",
        "    \n",
        "#     # # initial a np array of shape (785,10) to store the sum of the derivatives\n",
        "#     # sum_derivatives = np.zeros(shape=(input.shape[1], probabilities.shape[1]))\n",
        "#     # # Batch number = 50\n",
        "#     # batch_number = input.shape[0]\n",
        "#     # # Loop through the batch\n",
        "#     # for i in range(batch_number):\n",
        "#     #     # Initialize a np array of shape (785,10) to zero\n",
        "#     #     derivative = np.zeros(shape=(input.shape[1], probabilities.shape[1]))\n",
        "#     #     # Consider each input with its corresponding output probabilities\n",
        "#     #     current_input = input[i]\n",
        "#     #     current_probability = probabilities[i]\n",
        "#     #     # Loop through all the 785 elements of  each input\n",
        "#     #     for j in range(current_input.shape[0]):\n",
        "#     #         product = current_input[j] * (current_probability - encode(target[i]))\n",
        "#     #         derivative[j] = product\n",
        "#     #     sum_derivatives = sum_derivatives + derivative\n",
        "#     # return sum_derivatives/batch_number\n",
        "    \n",
        "#     # probabilities is of shape (50, 10)\n",
        "#     # input is of shape (50, 785)\n",
        "#     # target is of shape (50,10)\n",
        "#     # sum_derivatives is of size (50, 785, 10)\n",
        "#     derivatives = np.zeros(shape=(50,785,10))\n",
        "#     w = probabilities - target\n",
        "#     for i in range(50):\n",
        "#       # current_w contains 10 outputs for each 10 neurons\n",
        "#       current_w = w[i]\n",
        "#       # current_input contains 785 entries\n",
        "#       current_input = input[i]\n",
        "#       for j in range(785):\n",
        "#         input_entry = current_input[j]\n",
        "#         derivative = input_entry * current_w\n",
        "#         derivatives[i][j] = derivative\n",
        "#     avg_derivative = np.mean(derivatives,axis=0)\n",
        "#     return avg_derivative\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def adjust_weights(derivative, previous_weights, alpha = 0.01):\n",
        "#     new_weights = previous_weights - (alpha * derivative)\n",
        "#     return new_weights\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  \n",
        "def calculate_derivatives(probabilities,input,target):\n",
        "  batch_size = 50\n",
        "  input_size = 785\n",
        "  output_size = 10\n",
        "  derivatives = np.zeros(shape=(batch_size,input_size,output_size))\n",
        "  diff = probabilities - target\n",
        "  for i in range(batch_size):\n",
        "    # current_diff contains 10 outputs for each 10 neurons\n",
        "    current_diff = diff[i]\n",
        "    # current_input contains 785 entries\n",
        "    current_input = input[i]\n",
        "    for j in range(input_size):\n",
        "      input_entry = current_input[j]\n",
        "      derivative = input_entry * current_diff\n",
        "      derivatives[i][j] = derivative\n",
        "  avg_derivative = np.mean(derivatives,axis=0)\n",
        "  return avg_derivative\n",
        "    \n",
        "def adjust_weights(derivative, previous_weights, alpha = 0.01):\n",
        "    new_weights = previous_weights - (alpha * derivative)\n",
        "    return new_weights"
      ],
      "metadata": {
        "id": "Oe276YlR4296"
      },
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {
        "id": "aaDq4wjMIkG5"
      },
      "outputs": [],
      "source": [
        "# train the neural network\n",
        "def train(training_data, training_target, layer, activation, batch_size=50):\n",
        "  \n",
        "  total_loss = 0\n",
        "  for i in range(0,training_data.shape[0],batch_size):\n",
        "    batch = training_data[i:i+ batch_size]\n",
        "    batch_target = training_target[i: i + batch_size]\n",
        "    batch_target = encode(np.array(batch_target))\n",
        "    \n",
        "    # forward pass\n",
        "    layer.forward(batch)\n",
        "    logits = layer.output\n",
        "    activation.forward(logits)\n",
        "    probabilities = activation.output \n",
        "\n",
        "    # calculate loss for current batch\n",
        "    loss = calculate_loss(probabilities, batch_target)\n",
        "    total_loss += loss\n",
        "    # backward pass\n",
        "    derivative = calculate_derivatives(probabilities, batch, batch_target)\n",
        "    new_weights = adjust_weights(derivative,layer.weights)\n",
        "    layer.weights = new_weights\n",
        "    print(i)\n",
        "  return total_loss,layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained network to make predictions\n",
        "\n",
        "def test(testing_data, testing_target,layer,activation, batch_size=50):\n",
        "  predictions = []\n",
        "  for i in range(0,testing_data.shape[0],batch_size):\n",
        "    test_batch = testing_data[i: i + batch_size]\n",
        "    test_batch_target = testing_target[i: i + batch_size]\n",
        "    test_batch_target = encode(np.array(testing_target[i: i + batch_size]))\n",
        "\n",
        "    # forward pass\n",
        "    layer.forward(test_batch)\n",
        "    logits = layer.output\n",
        "    activation.forward(logits)\n",
        "    probabilities = activation.output\n",
        "\n",
        "    # obtain predicted values\n",
        "    prediction = np.argmax(probabilities, axis=1)\n",
        "    predictions.extend(prediction.tolist())\n",
        "  return predictions\n",
        "  "
      ],
      "metadata": {
        "id": "WPj2FZhuJxnu"
      },
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = Layer_Dense()\n",
        "activation = Activation_Softmax()\n",
        "total_loss, trained_layer = train(training_data, training_target, layer, activation)\n",
        "predictions = test(testing_data, testing_target,trained_layer,activation)"
      ],
      "metadata": {
        "id": "kaL4E2KIS1E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(testing_target, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9EVFyHWJUQg",
        "outputId": "f5ec91dd-781b-4e68-f405-8dd7534206b2"
      },
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 921    0   21    7    2   19    6    3    1    0]\n",
            " [   0 1118    4    3    0    3    2    2    3    0]\n",
            " [   2    9  962   10    5    8    9    9   13    5]\n",
            " [   0    0   32  906    1   48    1    6    8    8]\n",
            " [   1    2   15    3  912    1    8    2    6   32]\n",
            " [   2    1   10   45   11  781    8    8   22    4]\n",
            " [  10    3   18    3   11   32  877    2    2    0]\n",
            " [   4   10   46   14    8    1    1  919    2   23]\n",
            " [   4   17   42   46   25   71    7   12  735   15]\n",
            " [   7    7   10   11   53   22    0   22    1  876]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(testing_target, predictions))"
      ],
      "metadata": {
        "id": "vhKdLTD8RmXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc78714-d69d-4c89-b115-e90cc77f8bef"
      },
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.95       980\n",
            "           1       0.96      0.99      0.97      1135\n",
            "           2       0.83      0.93      0.88      1032\n",
            "           3       0.86      0.90      0.88      1010\n",
            "           4       0.89      0.93      0.91       982\n",
            "           5       0.79      0.88      0.83       892\n",
            "           6       0.95      0.92      0.93       958\n",
            "           7       0.93      0.89      0.91      1028\n",
            "           8       0.93      0.75      0.83       974\n",
            "           9       0.91      0.87      0.89      1009\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(testing_target, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5ef_Am6KRq2",
        "outputId": "e3b053e5-fcbd-4dca-8078-d1c698dd9a7f"
      },
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADe6ICI0V7B7",
        "outputId": "207ae991-421f-4eb8-9211-c1fb726989f3"
      },
      "execution_count": 402,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3067.999129093812"
            ]
          },
          "metadata": {},
          "execution_count": 402
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}